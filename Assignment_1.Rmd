---
title: 'Assignement 1: Linear Regression'
author: "Bob Merkus, Tom Hartgers, Benine Karssen, Lucas Graas"
date: "12/2/2021"
output: html_document
---

```{r, warning = F}
source("data_import.R")
```

**1 Introduction**
In the following assignment we will explore the relation between the (academic) degree of gamers and their score on the satisfaction with life scale. After exploring the dataset, removing outliers and exploring the variable distribution and bivariate relations between the variables we will start with a simple linear regression on the aforementioned variables, after which we will statrt controlling for age and hours played through a multiple regression analysis. Through a model comparison we will subsequently decide which of our models predicts the satisfaction with life score best. 

**1.1 Dataset - Lucas**
Detection and removal of outliers per variable
```{r, warning = F}

  # Detecting and removing outliers with frequency plots
#SWL_T
barplot_SWL_T <- ggplot(clean_data, aes(x = SWL_T)) + 
  geom_bar(stat = "count")
barplot_SWL_T
summary(clean_data$SWL_T)

#SPIN_T
barplot_SPIN_T <- ggplot(clean_data, aes(x = SPIN_T)) +
  geom_bar(stat = "count") 
barplot_SPIN_T
summary(clean_data$SPIN_T)

#AGE
barplot_Age <- ggplot(clean_data, aes(x = Age)) + 
  geom_bar(stat = "count")
barplot_Age
summary(clean_data$Age)

#Hours
clean_data <- clean_data[clean_data$Hours < 126,]
barplot_Hours <- ggplot(clean_data, aes(x = Hours)) + 
  geom_bar()
summary(clean_data$Hours)
barplot_Hours

#Degree 
barplot_Degree <- ggplot(clean_data, aes(x = Degree)) + 
  geom_bar(stat = "count")
summary(clean_data$Degree)
barplot_Degree

#Game 
barplot_Game <- ggplot(clean_data, aes(y = Game)) + 
  geom_bar(stat = "count")
summary(clean_data$Game)
barplot_Game

#Playstyle
barplot_Playstyle <- ggplot(clean_data, aes(x = Playstyle)) + 
  geom_bar(stat = "count")
barplot_Playstyle
summary(clean_data$Playstyle)

```

Next, we will be turning categories into dummy variables based on frequency plots. The most frequently occuring value per category is left out as baseline value. The most frequent Degree is High school diploma, the most frequent game is League of Legends & the most frequent Playstyle is multiplayer. These values will be considered as baseline values for dummy variable creation.

```{r}
# expand tibble with dummy variables
clean_data <- clean_data %>% 
  mutate(
    Degree.Bachelor = ifelse(Degree=="Bachelor", 1, 0),
    Degree.Master = ifelse(Degree=="Master", 1, 0),
    Degree.None = ifelse(Degree=="None", 1, 0),
    Degree.PhD = ifelse(Degree=="Ph.D., Psy. D., MD", 1, 0),
    Game.CS = ifelse(Game=="Counter Strike", 1, 0),
    Game.Destiny = ifelse(Game=="Destiny", 1, 0),
    Game.Diablo = ifelse(Game=="Diablo 3", 1, 0),
    Game.GW = ifelse(Game=="Guild Wars 2", 1, 0),
    Game.Hearthstone = ifelse(Game=="Hearthstone", 1, 0),
    Game.HOTS = ifelse(Game=="Heroes of the Storm", 1, 0),
    Game.Skyrim = ifelse(Game=="Skyrim", 1, 0),
    Game.Starcraft = ifelse(Game=="Starcraft 2", 1, 0),
    Game.WoW = ifelse(Game=="World of Warcraft", 1, 0),
    Game.Other = ifelse(Game=="Other", 1, 0),
    Playstyle.Singleplayer = ifelse(Playstyle=="Singleplayer", 1, 0)
  )
clean_data %>% 
  select(-c(1:7)) %>% 
  summary()

```
We can see that all dummy variables have a minimum value of 0 and a maximum value of 1, showing we succesfully added the dummy variables.

**1.2 Research questions**
**1.3 Data exploration**
**1.3.1 Bivariate Relations**
**1.3.2 Variable distributions**

**2 Simple Linear Regression**  

```{r}
out1 <- lm(clean_data$SWL_T ~ clean_data$Degree, data = clean_data)
```

**2.1 Coefficients - Benine**


**2.2 P-values - Benine**


**2.3 Confidence Interval (CI) - Tom** 
Compute the confidence intervals for the parameters of the model with a 95% confidence level.
```{r}
confint(out1)
```
None of the confidence intervals contain the value 0. Therefore we can be 95% sure that if we compute our analysis an infinite number of times, 95% of all confidence intervals will surround the true value of the parameters. As none of the intervals contain the value of 0, this is not a probable value. Therefore we can reject the null hypothesis of our model. 

**2.4 Model fit - Tom** 
For assessing the model fit we can use the R-squared statistic. 
```{r}
summary(out1)
```
The R-squared statistic shows us that our model significantly explains 1.422% of the variance in SWL_T scores, with an F-statistic of 46.06 and an associated p-value < 0.05.  

**3 Multiple Linear Regression - Bob**
```{r}

out2 <- lm(data = clean_data, formula = clean_data$SWL_T ~ clean_data$Degree.Bachelor + clean_data$Degree.Master + clean_data$Degree.None + clean_data$Degree.PhD)

```


**3.1 Compare models (RMSE, AIC, BIC)**
```{r}

# out2 %>% AIC
# out2 %>% BIC


```


**3.2 Interpret final model**
```{r}

```


**3.3 Conclusions regarding model**
```{r}

```


**3.3.1 Inference**
```{r}

```


**3.3.2 Predictions** 
```{r}
# out2 %>% predict
```

